{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "### Web Scraping Best Practices:\n",
    "\n",
    "- Never scrape more frequently than you need to.\n",
    "- Consider caching the content you scrape so that it’s only downloaded once.\n",
    "- Build pauses into your code using functions like time.sleep() to keep from overwhelming servers with too many requests too quickly.\n",
    "- Video von [neuefische](https://www.youtube.com/watch?v=HMSe8WTNmFg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "The library we will use today to find fishes we can gift Larissa for christmas is [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). It is a library to extract data out of HTML and XML files.\n",
    "\n",
    "The first thing we’ll need to do to scrape a web page is to download the page. We can download pages using the Python requests.\n",
    "\n",
    "The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us. There are several different types of requests we can make using requests, of which GET is just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Blueground - robots.txt\n",
    "User-agent: *  <br>\n",
    "Disallow: /book <br>\n",
    "Disallow: /book-failed<br>\n",
    "Disallow: /book-thankyou<br>\n",
    "Disallow: /expired<br>\n",
    "Disallow: /feedback<br>\n",
    "Disallow: /guests<br>\n",
    "Disallow: /nps<br>\n",
    "Disallow: /offers<br>\n",
    "Disallow: /payment-failed<br>\n",
    "Disallow: /payment-thankyou<br>\n",
    "Disallow: /payments<br>\n",
    "Disallow: /rating<br>\n",
    "Disallow: /users<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/ist.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lon.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/par.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/vie.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/dxb.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/mia.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/nyc.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/sfo.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lax.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/bos.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/wdc.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/chi.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/sea.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/den.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/atx.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/zrh.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/ber.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/mad.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/bcn.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lis.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/bsl.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/hkg.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/cph.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/lux.xml<br>\n",
    "Sitemap: https://www.theblueground.com/sitemap-images/sgp.xml<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the content of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content of the website\n",
    "# Blueground - London\n",
    "# https://www.theblueground.com/furnished-apartments-london-uk\n",
    "page = requests.get(\"https://www.theblueground.com/furnished-apartments-london-uk\")\n",
    "html = page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the BeautifulSoup library to parse this document, and extract the information from it.\n",
    "\n",
    "We first have to import the library, and create an instance of the BeautifulSoup class to parse our document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html and save it into a BeautifulSoup instance\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we have more than one element with the same tag? Then we can just use the ```.find_all()``` method of BeautifulSoup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for the Apartment/Studio Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names = bs.find_all(class_=\"listing-name\")\n",
    "\n",
    "object_names_lst = (object_name.get_text() for object_name in object_names)\n",
    "object_names_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_names_lst = [object_name.strip() for object_name in object_names_lst]\n",
    "object_names_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### availabe - Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tags = bs.find_all(class_=\"availability__available\")\n",
    "\n",
    "available_tag_lst = (available_tag.get_text() for available_tag in available_tags)\n",
    "available_tag_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tag_lst = [available_tag.strip() for available_tag in available_tag_lst]\n",
    "available_tag_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### available from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availables = bs.find_all(class_=\"availability__date\")\n",
    "available_lst = (available.get_text() for available in availables)\n",
    "available_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_lst = [available.strip() for available in available_lst]\n",
    "available_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price - currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price__currency\n",
    "price_currencys = bs.find_all(class_= \"price__currency\")\n",
    "price_currencys_lst = [price_currency.get_text() for price_currency in price_currencys]\n",
    "price_currencys_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_currencys_lst = [price_currency.strip() for price_currency in price_currencys_lst]\n",
    "price_currencys_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price - amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = bs.find_all(class_= \"price__amount\")\n",
    "prices_lst = [price.get_text() for price in prices]\n",
    "prices_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_lst = [price.strip() for price in prices_lst]\n",
    "prices_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price per month etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_month = bs.find_all(class_= \"monthly-price__suffix monthly-price__suffix--mobile\")\n",
    "prices_month_lst = [price_month.get_text() for price_month in prices_month]\n",
    "prices_month_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_month_lst = [price_month.strip() for price_month in prices_month_lst]\n",
    "prices_month_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_month_lst = [price_month.replace('/', '') for price_month in prices_month_lst]\n",
    "prices_month_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_month_lst = [price_month.replace('mo', 'month') for price_month in prices_month_lst]\n",
    "prices_month_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complett description of the appartement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions= bs.find_all(class_=\"listing-amenities\")\n",
    "descriptions_lst = [description.get_text() for description in descriptions]\n",
    "descriptions_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_lst = [description.strip() for description in descriptions_lst]\n",
    "descriptions_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main-amenities  of the appartement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_amenities= bs.find_all(class_=\"main-amenities\")\n",
    "main_amenities_lst = [main_amenitie.get_text() for main_amenitie in main_amenities]\n",
    "main_amenities_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_amenities_lst = [main_amenitie.strip() for main_amenitie in main_amenities_lst]\n",
    "main_amenities_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main_amenities_amenity seperated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_amenities_amenitys = bs.find_all(class_=\"main-amenities__amenity\")\n",
    "main_amenities_amenity_lst = [main_amenitie_amenity.get_text() for main_amenitie_amenity in main_amenities_amenitys]\n",
    "main_amenities_amenity_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_amenities_amenity_lst = [main_amenitie.strip() for main_amenitie in main_amenities_amenity_lst]\n",
    "main_amenities_amenity_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rest_amenities of apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_amenities = bs.find_all(class_=\"rest-amenities\")\n",
    "rest_amenities_lst = [rest_amenity.get_text() for rest_amenity in rest_amenities]\n",
    "rest_amenities_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_amenities_lst = [rest_amenity.strip() for rest_amenity in rest_amenities_lst]\n",
    "rest_amenities_lst[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen eines DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['object_name'] = pd.Series(object_names_lst)\n",
    "df['available_tag'] = pd.Series(available_tag_lst)\n",
    "df['available'] = pd.Series(available_lst)\n",
    "df['description'] = pd.Series(descriptions_lst)\n",
    "df['main_amenities'] = pd.Series(main_amenities_lst)\n",
    "#df['main_amenities_amenity'] =pd.Series( main_amenities_amenity_lst)\n",
    "df['rest_amenities'] = pd.Series(rest_amenities_lst)\n",
    "df['price_currencys'] = pd.Series(price_currencys_lst)\n",
    "df['prices'] = pd.Series(prices_lst)\n",
    "df['prices_month'] = pd.Series(prices_month_lst)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the actual DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.datetime.today().strftime('%Y-%m-%d %H:%M') # to set the date in the csv filename\n",
    "df.to_csv('spotahome_{}.csv'.format(today), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information to get data in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look for 'class=\"blank-slate__criteria\"' , this will show us the last page of the infinite-scroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&\n",
    "# for _ in range(7):\n",
    "#     time.sleep(3)\n",
    "#     if _ == 0:\n",
    "#         page = requests.get(link + offset=1&items=18)\n",
    "#         html = page.content\n",
    "#     else:\n",
    "#         print(link + f'/offset={_}&items=18')\n",
    "#         page = requests.get(link + f'/offset={_}&items=18')\n",
    "#         html = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 1\n",
    "\n",
    "while bs.find_all(class_=(\"blank-slate__criteria\")) == False:\n",
    "    time.sleep(5)\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    html = page.content\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    print(weblink + f'/offset={ pagesite }&items=18')\n",
    "    pagesite += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give us the correct url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 1\n",
    "\n",
    "while pagesite < 7:\n",
    "    #time.sleep(5)\n",
    "    #page = requests.get(weblink +  f'/offset={ pagesite }&items=18')\n",
    "    #html = page.content\n",
    "    #bs = BeautifulSoup(html, 'html.parser')\n",
    "    print(weblink + f'offset={ pagesite }&items=18')\n",
    "    pagesite += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website not found:\n",
    "\n",
    "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=18&items=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content of the website\n",
    "# Blueground - London\n",
    "# https://www.theblueground.com/furnished-apartments-london-uk\n",
    "page_not_found = requests.get(\"https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=15&items=18\")\n",
    "html_not_found = page_not_found.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html and save it into a BeautifulSoup instance\n",
    "bs_not_found = BeautifulSoup(html_not_found, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_slates = bs_not_found.find_all(class_=\"blank-slate__criteria\")\n",
    "\n",
    "blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "blank_slates_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "blank_slates_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We try to shop the loop with 'class=\"blank-slate__criteria\"' to see, if we have reached the end of the infinite-scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with an Inifiy - Website - Scrolling\n",
    "\n",
    "https://medium.com/@harshvb7/scraping-from-a-website-with-infinite-scrolling-7e080ea8768e\n",
    "\n",
    "https://stackoverflow.com/questions/69046183/how-do-i-scrape-a-website-with-an-infinite-scroller\n",
    "\n",
    "https://stackoverflow.com/questions/64527791/scraping-an-infinite-scroll-page\n",
    "\n",
    "https://stackoverflow.com/questions/12519074/scrape-websites-with-infinite-scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startlink: https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=12&items=18\n",
      "We are looking for: We’re sorry! We can’t seem to find any apartments that match your search.\n",
      "<class 'str'>\n",
      "We currently have: []\n",
      "<class 'list'>\n",
      "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=12&items=18\n",
      "<generator object <genexpr> at 0x132eb1510>\n",
      "[]\n",
      "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=13&items=18\n",
      "<generator object <genexpr> at 0x132eb1a50>\n",
      "[]\n",
      "https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&offset=14&items=18\n",
      "<generator object <genexpr> at 0x1331d3f90>\n",
      "['We’re sorry! We can’t seem to find any apartments that match your search.']\n"
     ]
    }
   ],
   "source": [
    "weblink = 'https://www.theblueground.com/furnished-apartments-london-uk?currency=GBP&language=en&'\n",
    "pagesite = 12\n",
    "\n",
    "# blank_slates = bs_not_found.find_all(class_=\"blank-slate__criteria\")\n",
    "# blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "# blank_slates_lst\n",
    "# blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "blank_slates_lst = []\n",
    "stop_loop = \"We’re sorry! We can’t seem to find any apartments that match your search.\"\n",
    "print(\"Startlink:\", weblink + f'offset={ pagesite }&items=18')\n",
    "print(\"We are looking for:\", stop_loop)\n",
    "print(type(stop_loop))\n",
    "print(\"We currently have:\", blank_slates_lst)\n",
    "print(type(blank_slates_lst))\n",
    "\n",
    "\n",
    "# https://flexiple.com/python/check-if-list-is-empty-python/\n",
    "# Solution 3: Using len() function\n",
    "# The len() function returns the number of items in a list. If the list is empty, it returns 0.\n",
    "while len(blank_slates_lst) == 0:\n",
    "    time.sleep(5)\n",
    "    page = requests.get(weblink +  f'offset={ pagesite }&items=18')\n",
    "    html = page.content\n",
    "    bs_loop = BeautifulSoup(html, 'html.parser')\n",
    "    print(weblink + f'offset={ pagesite }&items=18')\n",
    "    pagesite += 1\n",
    "\n",
    "    blank_slates = bs_loop.find_all(class_=\"blank-slate__criteria\")\n",
    "    blank_slates_lst = (blank_slate.get_text() for blank_slate in blank_slates)\n",
    "    print(blank_slates_lst)\n",
    "    blank_slates_lst = [blank_slate.strip() for blank_slate in blank_slates_lst]\n",
    "    print(blank_slates_lst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_bs4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9af5746f41ef31dea01f09ffb6ba9bd116b901566dc69a02f72533c94f316243"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
